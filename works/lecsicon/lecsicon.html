<!doctype html>
<html lang="en" data-predefined-style="true" data-css-presets="true" data-css-preset data-typography-preset>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Lecsicon</title>
    <link
        href="https://freight.cargo.site/t/original/i/015d3e4e00b711811382785641c2e3bec00ac0af1475575a082b8295dfccfa27/download---2024-04-17T150654.577.ico"
        rel="shortcut icon">
    <link href="https://karlie.theunthoughts.com/rss" rel="alternate" type="application/rss+xml"
        title="karlie_zhao feed">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    <link
        href="https://fonts.googleapis.com/css2?family=Heebo:wght@100..900&family=Mukta:wght@200;300;400;500;600;700;800&display=swap"
        rel="stylesheet">
    <link href="//fonts.googleapis.com/css?family=Alegreya Sans:400,400italic,700,700italic&c=3264474720&" id=""
        rel="stylesheet" type="text/css" />
    <link rel="stylesheet" href="../../css/cargo.css">
    <link rel="stylesheet" href="../../css/basics.css">
    <script src="../../js/jquery-3.7.1.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/p5@1.5.0/lib/p5.js"></script>

</head>

<body class="workpage">
    <div grid-row="" grid-pad="2">
        <h2><a href="../../index.html">Back</a></h2>
        <br>
        <div grid-row="" grid-pad="2" grid-gutter="4" grid-responsive="">
            <div grid-col="x11" grid-pad="2" class="">
                <div style="text-align: right">
                    <img src="./cover.png" image-gallery-col="x11">
                </div>
            </div>
            <div grid-col="x11" grid-pad="2" class="">
                <img src="./book2.jpg" width="93%">
            </div>
        </div>
        <br> <br>

        <div grid-row="" grid-pad="2" grid-gutter="4" grid-responsive="">
            <div grid-col="3" grid-pad="2">
                <h1><b>Lecsicon</b><br></h1>
                <br>
                website, book<br>Jun 2023 - Feb 2024<b><br><br>
                    <br>
                    Tools<br></b>Node.js, Python, GPT-3.5, GPT-4<b><a href="https://johncheung.feedia.co/"></a></b><br>
            </div>
            <div grid-col="9" grid-pad="2" class="">Lecsicon is a collection of more than 24,000 <i><a
                        href="https://www.poetryfoundation.org/search?query=Acrostic"
                        target="_blank"><u>acrostics</u></a></i> generated by OpenAI's language model
                GPT.&nbsp;Following a specific prompt, GP made a sentence with a series of words whose first letters
                sequentially spelled out the given word. At a large scale, thi process gives rise to intriguing
                behavioral patterns in th model. The resulting acrostics serve as a conduit between machine
                comprehension and human interpretation, seeking to elicit gripping reflections on the nature of this
                literary device and its role in meaning making.&nbsp;<br><br>
                For this project, I utilized a comprehensive collection of English words obtained from the <i><a
                        href="https://elexicon.wustl.edu/" target="_blank"><u>English Lexicon Project </u></a></i>and
                used the API for OpenAI’s GPT to generate acrostic sentences to each word. I provided GPT with a
                particular prompt and collected the generated acrostics into a <a
                    href="https://karliezhao.github.io/lecsicon/" target="_blank"><i><u>browser-based interactive
                            artwork</u></i>,</a> which <i></i>was published in the Spring 2023 issue of the digital
                journal <i><a href="https://thenewriver.us/lecsicon/" target="_blank"><u>The New River</u></a>.</i> It
                was later on produced as a physical book/dictionary.<br>

                <br>
                <a href="https://karliezhao.github.io/lecsicon/" target="_blank" class="image-link">
                    
                    <img src="./lecsicon_1.gif" image-gallery-col="x12">
                </a><br>
                <br>
                Here is my prompted for GPT 4:&nbsp;<small>(You are, of course, welcome to grab it and play the game
                    with your Chatbot.)</small><br>



                <br>
                <i>"I will give you a word. Make a sentence or phrase with a series of words whose first letters
                    sequentially spell out my word. Your sentence doesn't have to have a strong semantic connection with
                    the word I give you.<br><br>Now make a sentence for /WORD/. Your response should only contain the
                    sentence you make. "</i><br><br>
                In response to my prompt, the model created acrostics in the form of sentences to each of the words
                provided. Thousands of word-sentence pairs compose this project. Including “Lecsicon: Linguists
                Enthusiastically Catalog Symbols, Interpreting Carefully Occurred Nuances.”<br>
                <br>

                <div style="text-align: right">

                    <img src="./installation.jpg" class="workpage-img-mid"><br></div>
                <div style="text-align: right"><small>Lecsicon as a video installation for exhibition “Do You Have the
                        Key?” <br>
                        at Rhode Island School of Design in May 2023. </small></div><br>
                <br>
                <img src="./read.jpeg" class="workpage-img-mid">
                <div style="text-align: right"><small>Lecsicon as a printed book.</small></div><br>
                <br>
                <h1><b>Behind the Scenes</b><br></h1>
                <br>
                The accuracy of GPT's responses, as usual, was not guaranteed. At times, one or two extra words slipped
                into the sentence. In extreme cases, the model rambled on and lost track of the initial instructions.
                Out of tens of thousands of attempts, with GPT 3.5, 30% of the responses strictly followed my rules; and
                with GPT 4, 60% of them.<br>

                <br>The following is a selection of both successful and unsuccessful acrostics generated by GPT
                throughout the multiple iterations of the projects.<br>

                <br>Unsuccessful examples include:

                <br>
                <ul>
                    <li>insomnia: I need some pills to sleep over insomnia.<br></li>
                    <li>
                        jumbo: Josh usually needs bigger overalls.<br></li>
                    <li>
                        white: We have icy hills to explore.<br></li>
                </ul>

                <br>Successful examples include:<ul>
                    <li>
                        activity: All children thrive in varied, invigorating tasks year-round.<br></li>
                    <li>
                        music: Many unexpected sounds indicate creativity.<br></li>
                    <li>
                        gender: Generations endlessly nurture diverse, equal respect.<br></li>
                </ul>
                <br>
                When one visits the Lecsicon web page, the successful word-sentence pairs are typed out letter-by-letter
                by a program. Beginning with a random word, the program scans the Lecsicon database, and strives to find
                a new word that has the smallest Levenshtein distance from the preceding word. For the printed book, the
                entries are sorted and rendered&nbsp;with python in a dictionary format.
                <br>
                <br>
                <div class="image-gallery" gid="3">
                    <img src="./inside1.png" image-gallery-col="x11">
                    <img src="./inside2.png" image-gallery-col="x11">
                </div><br>
                Linguistic devices like acrostics captivate people like me because there is a hidden layer behind
                putting words together following certain mechanisms. In Lecsicon, the resulting sentences provide a
                greater context for the original words and reveal new perspectives. But I believe it is not a
                coincidence that GPT makes sentences that relate to the original word's meaning. Instead, it is a
                deliberate calculation and balancing process to capture words based on their relations to each other: a
                ghost wandering through a latent word vector space. Any word in such a space is nothing but the
                linguistic associations around it, based on statistical computation of the patterns of the text humans
                have produced. Sentences emerge from their context, and perhaps that's why some entries are intriguing
                and exciting, such as “snob: Surely, no one believes”, or “date: Dinner and theater experience.”<br><br>
                <br>
                <div style="text-align: center;">
                    <img src="./open.jpg" class="workpage-img-large"><br>
                </div>
            </div>
        </div>
    </div>
    <script src="../../js/main.js"></script>
</body>

</html>